{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(15000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 15 seconds\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 5\n",
    "%autosave 15\n",
    "\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import sklearn\n",
    "from sklearn.decomposition import TruncatedSVD \n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.svm import SVR, SVC, LinearSVC\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression , SGDClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk import word_tokenize    \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    " \n",
    "from build_db import Category, Base, WebPage\n",
    "engine = create_engine('sqlite:///features.db', encoding='utf8', convert_unicode=True)\n",
    "\n",
    "Base.metadata.bind = engine\n",
    "DBSession = sessionmaker(bind=engine)\n",
    "session = DBSession()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "statement = session.query(WebPage).statement\n",
    "dataframe = pd.read_sql(statement.compile(engine), session.query(WebPage).session.bind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4480, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = dataframe['cat_id']\n",
    "X = pd.DataFrame(dataframe['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform label to numerical values\n",
    "le = LabelEncoder()\n",
    "le.fit(y)\n",
    "y_num = pd.Series(le.transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [i for i in tokens if i not in string.punctuation]\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(pd.DataFrame(X['text']), y_num, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pipeline using singular value decomposition\n",
    "clf = Pipeline([('vect', CountVectorizer(tokenizer=tokenize, strip_accents='unicode', stop_words='english')), \n",
    "                ('tfidf', TfidfTransformer(sublinear_tf=True)),  \n",
    "                ('svd', TruncatedSVD()),\n",
    "                ('clf',SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=20, random_state=12)),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "     ...     penalty='l2', power_t=0.5, random_state=12, shuffle=True, verbose=0,\n",
       "       warm_start=False))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train['text'], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = clf.predict(X_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_components = [300, 400, 500, 700, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:  1.2min\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 30.0min finished\n"
     ]
    }
   ],
   "source": [
    "estimator = GridSearchCV(clf, dict(svd__n_components=n_components), verbose=True)\n",
    "estimator.fit(X['text'], y_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = estimator.predict(X_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54821428571428577"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 99,  64,  18,   0,   2,   4],\n",
       "       [  7, 142,  11,   0,   4,   7],\n",
       "       [  8,  20, 124,   0,   0,   0],\n",
       "       [  1,   2,   0,   0,   0,   0],\n",
       "       [  7,  14,   7,   0,  35,   2],\n",
       "       [ 16,  43,  13,   0,   1,  21]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.53      0.61       187\n",
      "          1       0.50      0.83      0.62       171\n",
      "          2       0.72      0.82      0.76       152\n",
      "          3       0.00      0.00      0.00         3\n",
      "          4       0.83      0.54      0.65        65\n",
      "          5       0.62      0.22      0.33        94\n",
      "\n",
      "avg / total       0.66      0.63      0.61       672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_test, predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_components = [600,700,800,900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV] svd__n_components=600 ...........................................\n",
      "[CV] .................. svd__n_components=600, score=0.537433 - 1.1min\n",
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:  1.1min\n",
      "[CV] svd__n_components=600 ...........................................\n",
      "[CV] .................. svd__n_components=600, score=0.605228 - 1.2min\n",
      "[Parallel(n_jobs=1)]: Done   2 jobs       | elapsed:  2.3min\n",
      "[CV] svd__n_components=600 ...........................................\n",
      "[CV] .................. svd__n_components=600, score=0.503351 - 1.1min\n",
      "[Parallel(n_jobs=1)]: Done   3 jobs       | elapsed:  3.4min\n",
      "[CV] svd__n_components=700 ...........................................\n",
      "[CV] .................. svd__n_components=700, score=0.536765 - 1.4min\n",
      "[Parallel(n_jobs=1)]: Done   4 jobs       | elapsed:  4.9min\n",
      "[CV] svd__n_components=700 ...........................................\n",
      "[CV] .................. svd__n_components=700, score=0.603887 - 1.5min\n",
      "[Parallel(n_jobs=1)]: Done   5 jobs       | elapsed:  6.4min\n",
      "[CV] svd__n_components=700 ...........................................\n",
      "[CV] .................. svd__n_components=700, score=0.500670 - 1.3min\n",
      "[Parallel(n_jobs=1)]: Done   6 jobs       | elapsed:  7.7min\n",
      "[CV] svd__n_components=800 ...........................................\n",
      "[CV] .................. svd__n_components=800, score=0.534091 - 2.9min\n",
      "[Parallel(n_jobs=1)]: Done   7 jobs       | elapsed: 10.5min\n",
      "[CV] svd__n_components=800 ...........................................\n",
      "[CV] .................. svd__n_components=800, score=0.605228 - 1.5min\n",
      "[Parallel(n_jobs=1)]: Done   8 jobs       | elapsed: 12.0min\n",
      "[CV] svd__n_components=800 ...........................................\n",
      "[CV] .................. svd__n_components=800, score=0.494638 - 1.5min\n",
      "[Parallel(n_jobs=1)]: Done   9 jobs       | elapsed: 13.5min\n",
      "[CV] svd__n_components=900 ...........................................\n",
      "[CV] .................. svd__n_components=900, score=0.534759 - 2.6min\n",
      "[Parallel(n_jobs=1)]: Done  10 jobs       | elapsed: 16.1min\n",
      "[CV] svd__n_components=900 ...........................................\n",
      "[CV] .................. svd__n_components=900, score=0.609920 - 4.4min\n",
      "[Parallel(n_jobs=1)]: Done  11 jobs       | elapsed: 20.5min\n",
      "[CV] svd__n_components=900 ...........................................\n",
      "[CV] .................. svd__n_components=900, score=0.502681 - 1.4min\n",
      "[Parallel(n_jobs=1)]: Done  12 jobs       | elapsed: 21.9min\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed: 21.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "     ...     penalty='l2', power_t=0.5, random_state=12, shuffle=True, verbose=0,\n",
       "       warm_start=False))]),\n",
       "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
       "       param_grid={'svd__n_components': [600, 700, 800, 900]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
       "       verbose=100)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = GridSearchCV(clf, dict(svd__n_components=n_components), verbose=100)\n",
    "estimator.fit(X['text'], y_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svd__n_components': 900}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = estimator.predict(X_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[102,  66,  15,   0,   2,   2],\n",
       "       [  6, 150,  11,   0,   2,   2],\n",
       "       [  5,  19, 127,   0,   0,   1],\n",
       "       [  1,   1,   0,   1,   0,   0],\n",
       "       [  6,  15,   6,   0,  36,   2],\n",
       "       [ 13,  38,  11,   0,   2,  30]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.55      0.64       187\n",
      "          1       0.52      0.88      0.65       171\n",
      "          2       0.75      0.84      0.79       152\n",
      "          3       1.00      0.33      0.50         3\n",
      "          4       0.86      0.55      0.67        65\n",
      "          5       0.81      0.32      0.46        94\n",
      "\n",
      "avg / total       0.72      0.66      0.65       672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_test, predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Art\n",
      "1123\n",
      "Business\n",
      "1257\n",
      "Education\n",
      "967\n",
      "Lifestyle\n",
      "19\n",
      "Sports\n",
      "447\n",
      "Tech\n",
      "667\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    print le.inverse_transform(i)\n",
    "    print len(y_num[y_num==i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pipeline using singular value decomposition\n",
    "clf = Pipeline([('vect', CountVectorizer(tokenizer=tokenize, strip_accents='unicode', stop_words='english')), \n",
    "                ('tfidf', TfidfTransformer(sublinear_tf=True)),  \n",
    "                ('svd', TruncatedSVD(n_components=900)),\n",
    "                ('clf',SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=20, random_state=12)),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "     ...     penalty='l2', power_t=0.5, random_state=12, shuffle=True, verbose=0,\n",
       "       warm_start=False))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train['text'], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.55      0.59       187\n",
      "          1       0.47      0.80      0.60       171\n",
      "          2       0.76      0.75      0.75       152\n",
      "          3       0.00      0.00      0.00         3\n",
      "          4       0.78      0.48      0.59        65\n",
      "          5       0.66      0.22      0.33        94\n",
      "\n",
      "avg / total       0.64      0.60      0.59       672\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alejandrocassis/anaconda3/envs/venv/lib/python2.7/site-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "predicted = clf.predict(X_test['text'])\n",
    "print classification_report(y_test, predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['serialized/mymodel.pkl',\n",
       " 'serialized/mymodel.pkl_01.npy',\n",
       " 'serialized/mymodel.pkl_02.npy',\n",
       " 'serialized/mymodel.pkl_03.npy',\n",
       " 'serialized/mymodel.pkl_04.npy',\n",
       " 'serialized/mymodel.pkl_05.npy',\n",
       " 'serialized/mymodel.pkl_06.npy',\n",
       " 'serialized/mymodel.pkl_07.npy',\n",
       " 'serialized/mymodel.pkl_08.npy',\n",
       " 'serialized/mymodel.pkl_09.npy']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf,\"serialized/mymodel.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimator = joblib.load(\"serialized/mymodel.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.55      0.59       187\n",
      "          1       0.47      0.80      0.60       171\n",
      "          2       0.76      0.75      0.75       152\n",
      "          3       0.00      0.00      0.00         3\n",
      "          4       0.78      0.48      0.59        65\n",
      "          5       0.66      0.22      0.33        94\n",
      "\n",
      "avg / total       0.64      0.60      0.59       672\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alejandrocassis/anaconda3/envs/venv/lib/python2.7/site-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "predicted = estimator.predict(X_test['text'])\n",
    "print classification_report(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'Tech'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.inverse_transform(estimator.predict(['Computers ipod apple iphone']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    algorithms math\n",
       "1               aasd\n",
       "2               aaaa\n",
       "dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(['algorithms math', 'aasd', 'aaaa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Art\n",
      "1123\n",
      "Business\n",
      "1257\n",
      "Education\n",
      "967\n",
      "Lifestyle\n",
      "19\n",
      "Sports\n",
      "447\n",
      "Tech\n",
      "667\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    print le.inverse_transform(i)\n",
    "    print len(y_num[y_num==i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
